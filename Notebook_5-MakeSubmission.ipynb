{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available: 1\n",
      "Tensorflow version: 2.4.0\n",
      "Using seed value: 20212042\n"
     ]
    }
   ],
   "source": [
    "#!apt-get update ; apt-get install -y graphviz libgraphviz-dev\n",
    "#%pip install pydot\n",
    "# %pip install tqdm\n",
    "# %pip install pandas\n",
    "# %pip install sklearn\n",
    "# %pip install pillow\n",
    "# %pip install seaborn\n",
    "from tensorflow import keras\n",
    "import tensorflow\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import functools\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from tensorflow.keras.preprocessing import image as imgproc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, MaxPool2D, GlobalMaxPool2D, Flatten, AveragePooling2D, LSTM, ConvLSTM2D\n",
    "from tensorflow.keras.layers import TimeDistributed, Bidirectional, GRU, Dense, Dropout, Conv3D, MaxPooling3D, GlobalMaxPool3D\n",
    "from tensorflow.keras.utils import Sequence, OrderedEnqueuer\n",
    "import tensorflow as tf\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "import tempfile\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "import random\n",
    "from datetime import datetime\n",
    "%load_ext tensorboard\n",
    "%matplotlib inline\n",
    "print(\"Num GPUs Available:\", len(tf.config.list_physical_devices('GPU')))\n",
    "print(\"Tensorflow version:\", tensorflow.__version__)\n",
    "\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    \n",
    "# Attempt to make runs more reproducible\n",
    "seed_value=20212042\n",
    "print(\"Using seed value: %d\" % seed_value)\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value) # tensorflow 2.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up paths\n",
    "base_dir = \"/workspace/C684_Assignment/\"\n",
    "processing_dir = os.path.join(base_dir, \"processing\")\n",
    "frames_dir = os.path.join(processing_dir, \"att_maps\")\n",
    "train_dir = os.path.join(base_dir, \"training\")\n",
    "train_frame_dir = os.path.join(train_dir, \"train_frames\")\n",
    "chkp_dir = os.path.join(train_dir, \"chkp\")\n",
    "if not os.path.exists(chkp_dir):\n",
    "    os.makedirs(chkp_dir)\n",
    "logs_dir = os.path.join(train_dir, \"logs\")\n",
    "if not os.path.exists(logs_dir):\n",
    "    os.makedirs(logs_dir)\n",
    "    \n",
    "# some global params\n",
    "SHORT_TERM_MODEL = False\n",
    "SIZE = (70, 70)\n",
    "USE_ATT_MAPS = True\n",
    "USE_AMNET_PRED = True\n",
    "ATT_MAPS = [ 0, 1, 2 ] # full list - [ 0, 1, 2 ]\n",
    "RGB = True\n",
    "FRAME_INDEXES = [0, 48, 96, 144] # full list - [0, 24, 48, 72, 96, 120, 144]\n",
    "BATCH_SIZE=16\n",
    "TRAINING_ITERATIONS=4\n",
    "EPOCHS=20\n",
    "MULTIPROCESSING=False\n",
    "WORKERS=8\n",
    "SPEARMAN_THRESHOLD = 999. # do not save model # 0.43 if SHORT_TERM_MODEL else 0.2\n",
    "CHANNELS = len(ATT_MAPS) * (3 if RGB else 1)\n",
    "NBFRAME = len(FRAME_INDEXES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    224000.000000\n",
       "mean          0.600106\n",
       "std           0.160918\n",
       "min           0.000000\n",
       "25%           0.487308\n",
       "50%           0.628983\n",
       "75%           0.726435\n",
       "max           1.000000\n",
       "Name: Y_pred, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load data\n",
    "amnet_preds = pd.read_csv(os.path.join(processing_dir, \"all_amnet_pred.csv\")).set_index(\"video\")\n",
    "amnet_preds[\"Y_pred\"] = MinMaxScaler().fit_transform(amnet_preds[\"Y_pred\"].values.reshape(-1, 1))\n",
    "display(amnet_preds[\"Y_pred\"].describe())\n",
    "dev_videos = pd.read_csv(os.path.join(processing_dir, \"ground_truth_template.csv\"))\n",
    "\n",
    "# train/test y_true histogram\n",
    "X_test = dev_videos[\"video\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Generator Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictionSequence(Sequence):\n",
    "    def __init__(self, X_set):\n",
    "        self.x = X_set\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x) // BATCH_SIZE\n",
    "    \n",
    "    def _load_images(self, batch):\n",
    "        images = np.zeros((len(batch), NBFRAME, SIZE[0], SIZE[1], CHANNELS))\n",
    "        for video_index, video in enumerate(batch):\n",
    "            for sequence_index, frame_index in enumerate(FRAME_INDEXES):\n",
    "                filename = \"video%s_%d_att.jpg\" % (video, frame_index)\n",
    "                pilimg = []\n",
    "                for img_index in ATT_MAPS:\n",
    "                    dirname = \"%s-%d\" % (train_frame_dir, img_index)\n",
    "                    img = imgproc.load_img(os.path.join(dirname, filename))\n",
    "                    if not RGB:\n",
    "                        img = img.convert('L')\n",
    "                    img = img.resize(SIZE)\n",
    "                    img = imgproc.img_to_array(img)\n",
    "                    pilimg.append(img)\n",
    "                images[video_index][sequence_index] = np.concatenate(pilimg, axis=2) / 255.\n",
    "        return images\n",
    "    \n",
    "    def _load_amnet_preds(self, batch):\n",
    "        batch_amnet_preds = np.zeros((len(batch), NBFRAME))\n",
    "        for video_index, video in enumerate(batch):\n",
    "            for sequence_index, frame_index in enumerate(FRAME_INDEXES):\n",
    "                frame_id = \"video%s_%d\" % (video, frame_index)\n",
    "                batch_amnet_preds[video_index][sequence_index] = amnet_preds.loc[frame_id, \"Y_pred\"]\n",
    "        return batch_amnet_preds\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        print(idx)\n",
    "        batch_x = self.x[idx * BATCH_SIZE:(idx + 1) * BATCH_SIZE]\n",
    "        batch_x_features = []\n",
    "        if USE_ATT_MAPS:\n",
    "            batch_x_features.append(self._load_images(batch_x))\n",
    "        if USE_AMNET_PRED:\n",
    "            batch_x_features.append(self._load_amnet_preds(batch_x))\n",
    "        return batch_x_features\n",
    "\n",
    "def make_generator(X_set, worker_count):\n",
    "    seq = PredictionSequence(X_set)\n",
    "    enq = OrderedEnqueuer(seq, use_multiprocessing=MULTIPROCESSING, shuffle=False)\n",
    "    enq.start(workers=worker_count, max_queue_size=1)\n",
    "    return enq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "WARNING:tensorflow:5 out of the last 19 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f5c00526af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "m2 = load_model(os.path.join(train_dir, \"chkp\", \"weights-0.2086-27_04_2021_20_07-0-5.hdf5\"))#\"weights-short-0.4418-25_04_2021_22_17-2-19.hdf5\"))\n",
    "Y_pred = m2.predict(make_generator(X_test, 1).get(), steps=125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video</th>\n",
       "      <th>short-term_memorability</th>\n",
       "      <th>nb_short-term_annotations</th>\n",
       "      <th>long-term_memorability</th>\n",
       "      <th>nb_long-term_annotations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>10007</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34</td>\n",
       "      <td>0.782686</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video  short-term_memorability  nb_short-term_annotations  \\\n",
       "1998  10007                      NaN                         34   \n",
       "\n",
       "      long-term_memorability  nb_long-term_annotations  \n",
       "1998                0.782686                        12  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dev_videos[\"long-term_memorability\"] = Y_pred\n",
    "display(dev_videos[-2:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "m2 = load_model(os.path.join(train_dir, \"chkp\", \"weights-short-0.4418-25_04_2021_22_17-2-19.hdf5\"))\n",
    "Y1_pred = m2.predict(make_generator(X_test, 1).get(), steps=125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video</th>\n",
       "      <th>short-term_memorability</th>\n",
       "      <th>nb_short-term_annotations</th>\n",
       "      <th>long-term_memorability</th>\n",
       "      <th>nb_long-term_annotations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>10007</td>\n",
       "      <td>0.896066</td>\n",
       "      <td>34</td>\n",
       "      <td>0.782686</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video  short-term_memorability  nb_short-term_annotations  \\\n",
       "1998  10007                 0.896066                         34   \n",
       "\n",
       "      long-term_memorability  nb_long-term_annotations  \n",
       "1998                0.782686                        12  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dev_videos[\"short-term_memorability\"] = Y1_pred\n",
    "display(dev_videos[-2:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_videos.to_csv(os.path.join(processing_dir, \"Andrey_Totev_20212042_predictions.csv\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
